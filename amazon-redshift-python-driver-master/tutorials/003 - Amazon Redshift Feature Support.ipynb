{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Amazon Redshift Feature Support"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Overview\n",
    "`redshift_connector` aims to support the latest and greatest features provided by Amazon Redshift so you can get the most out of your data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## COPY and UNLOAD Support - Amazon S3\n",
    "`redshift_connector` provides the ability to `COPY` and `UNLOAD` data from an Amazon S3 bucket. Shown below is a sample workflow which copies and unloads data from an Amazon S3 bucket"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Upload the following text file to an Amazon S3 bucket and name it `category_csv.txt`\n",
    "\n",
    "```text\n",
    "    12,Shows,Musicals,Musical theatre\n",
    "    13,Shows,Plays,\"All \"\"non-musical\"\" theatre\"\n",
    "    14,Shows,Opera,\"All opera, light, and \"\"rock\"\" opera\"\n",
    "    15,Concerts,Classical,\"All symphony, concerto, and choir concerts\"\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import redshift_connector\n",
    "\n",
    "with redshift_connector.connect(\n",
    "    host='examplecluster.abc123xyz789.us-west-1.redshift.amazonaws.com',\n",
    "    database='dev',\n",
    "    user='awsuser',\n",
    "    password='my_password'\n",
    ") as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"create table category (catid int, cargroup varchar, catname varchar, catdesc varchar)\")\n",
    "            cursor.execute(\"copy category from 's3://testing/category_csv.txt' iam_role 'arn:aws:iam::123:role/RedshiftCopyUnload' csv;\")\n",
    "            cursor.execute(\"select * from category\")\n",
    "            print(cursor.fetchall())\n",
    "            cursor.execute(\"unload ('select * from category') to 's3://testing/unloaded_category_csv.txt'  iam_role 'arn:aws:iam::123:role/RedshiftCopyUnload' csv;\")\n",
    "            print('done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After executing the above code block, we can see the requested data was unloaded into the following file, `unloaded_category_csv.text0000_part00`, in the specified Amazon s3 bucket\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datatype Support\n",
    "`redshift_connector` supports Amazon Redshift specific datatypes in order to provide users integration of their data into Python projects. Please see the projects [README](https://github.com/aws/amazon-redshift-python-driver/blob/master/README.rst) for a list of supported datatypes."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
